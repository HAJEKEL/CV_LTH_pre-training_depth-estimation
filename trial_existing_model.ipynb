{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HAJEKEL/CV_LTH_pre-training_depth-estimation/blob/main/trial_existing_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkHg86FEM9dy",
        "outputId": "2d5cecbd-53dc-4c78-b218-ff3a29189e61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/.shortcut-targets-by-id/1kbr0lOVBd0ZwibVk1AvJDKkTpt1k440d/CV_LTH_pre-training_depth-estimation_experiments\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My Drive/CV_LTH_pre-training_depth-estimation_experiments\n",
        "import os\n",
        "import h5py\n",
        "import math\n",
        "import time\n",
        "import collections\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "#import models.resnet as resnet\n",
        "import cv2\n",
        "import numpy as np\n",
        "# import dataset\n",
        "import PIL.Image as Image\n",
        "from IPython.display import clear_output\n",
        "import network.FCRN as FCRN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irB1vmw2M9d3",
        "outputId": "80ed9770-deb6-416e-ea1c-4dfff45daf95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda available using gpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> model created.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (conv2): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (upSample): UpProj(\n",
              "    (layer1): UpProjModule(\n",
              "      (unpool): Unpool()\n",
              "      (upper_branch): Sequential(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "        (batchnorm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (batchnorm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (bottom_branch): Sequential(\n",
              "        (conv): Conv2d(1024, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (layer2): UpProjModule(\n",
              "      (unpool): Unpool()\n",
              "      (upper_branch): Sequential(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "        (batchnorm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (batchnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (bottom_branch): Sequential(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (layer3): UpProjModule(\n",
              "      (unpool): Unpool()\n",
              "      (upper_branch): Sequential(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "        (batchnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (batchnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (bottom_branch): Sequential(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (layer4): UpProjModule(\n",
              "      (unpool): Unpool()\n",
              "      (upper_branch): Sequential(\n",
              "        (conv1): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "        (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (batchnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (bottom_branch): Sequential(\n",
              "        (conv): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (conv3): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bilinear): Upsample(size=(228, 304), mode='bilinear')\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "output_shape=(228,304)\n",
        "lr=0.001\n",
        "momentum=0.9\n",
        "weight_decay=0.01\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device='cuda'\n",
        "    print('cuda available using gpu')\n",
        "else:\n",
        "    device='cpu'\n",
        "    print('cuda not available running on cpu')\n",
        "\n",
        "model = FCRN.ResNet(output_size=(228,304),pretrained=True)\n",
        "print(\"=> model created.\")\n",
        "start_epoch = 0\n",
        "\n",
        "# different modules have different learning rate\n",
        "train_params = [{'params': model.get_1x_lr_params(), 'lr': lr},\n",
        "                {'params': model.get_10x_lr_params(), 'lr': lr * 10}]\n",
        "\n",
        "optimizer = torch.optim.SGD(train_params, lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "model.to(device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "StWuQffSM9d5"
      },
      "outputs": [],
      "source": [
        "# # checkpoint=torch.load(\"/home/olaf/DLC/CV_LTH_Pre-training/Detection/weight/imagenet_weight.pt\")\n",
        "\n",
        "# model=torchvision.models.resnet50(weights='IMAGENET1K_V1') #is hetzelfde als onze weight file\n",
        "# model.train()\n",
        "\n",
        "# num_features = model.fc.in_features\n",
        "# print(model)\n",
        "# upsample_block = nn.Sequential(\n",
        "#     nn.Upsample(scale_factor=2),\n",
        "# )\n",
        "# model.fc= nn.Upsample(scale_factor=2) # hier moet je dus aanpassen maar de input shape is 2048, data collecter werkt voor mij lokaal wel\n",
        "# # print(model.fc)\n",
        "# print(model.device())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Ltt4xUZEM9d6"
      },
      "outputs": [],
      "source": [
        "\n",
        "def h5_loader(path):\n",
        "    h5f = h5py.File(path, \"r\")\n",
        "    rgb = np.array(h5f['rgb'])\n",
        "    rgb = np.transpose(rgb, (1, 2, 0))\n",
        "    \n",
        "    rgb=Image.fromarray(rgb)\n",
        "    # \n",
        "    depth = Image.fromarray(np.array(h5f['depth']))\n",
        "    return rgb, depth\n",
        "\n",
        "def log10(x):\n",
        "    \"\"\"Convert a new tensor with the base-10 logarithm of the elements of x. \"\"\"\n",
        "    return torch.log(x) / math.log(10)\n",
        "\n",
        "class Result(object):\n",
        "    def __init__(self):\n",
        "        self.irmse, self.imae = 0, 0\n",
        "        self.mse, self.rmse, self.mae = 0, 0, 0\n",
        "        self.absrel, self.lg10 = 0, 0\n",
        "        self.delta1, self.delta2, self.delta3 = 0, 0, 0\n",
        "        self.data_time, self.gpu_time = 0, 0\n",
        "\n",
        "    def set_to_worst(self):\n",
        "        self.irmse, self.imae = np.inf, np.inf\n",
        "        self.mse, self.rmse, self.mae = np.inf, np.inf, np.inf\n",
        "        self.absrel, self.lg10 = np.inf, np.inf\n",
        "        self.delta1, self.delta2, self.delta3 = 0, 0, 0\n",
        "        self.data_time, self.gpu_time = 0, 0\n",
        "\n",
        "    def update(self, irmse, imae, mse, rmse, mae, absrel, lg10, delta1, delta2, delta3, gpu_time, data_time):\n",
        "        self.irmse, self.imae = irmse, imae\n",
        "        self.mse, self.rmse, self.mae = mse, rmse, mae\n",
        "        self.absrel, self.lg10 = absrel, lg10\n",
        "        self.delta1, self.delta2, self.delta3 = delta1, delta2, delta3\n",
        "        self.data_time, self.gpu_time = data_time, gpu_time\n",
        "\n",
        "    def evaluate(self, output, target):\n",
        "        valid_mask = target > 0\n",
        "        output = output[valid_mask]\n",
        "        target = target[valid_mask]\n",
        "\n",
        "        abs_diff = (output - target).abs()\n",
        "\n",
        "        self.mse = float((torch.pow(abs_diff, 2)).mean())\n",
        "        self.rmse = math.sqrt(self.mse)\n",
        "        self.mae = float(abs_diff.mean())\n",
        "        self.lg10 = float((log10(output) - log10(target)).abs().mean())\n",
        "        self.absrel = float((abs_diff / target).mean())\n",
        "\n",
        "        maxRatio = torch.max(output / target, target / output)\n",
        "        self.delta1 = float((maxRatio < 1.25).float().mean())\n",
        "        self.delta2 = float((maxRatio < 1.25 ** 2).float().mean())\n",
        "        self.delta3 = float((maxRatio < 1.25 ** 3).float().mean())\n",
        "        self.data_time = 0\n",
        "        self.gpu_time = 0\n",
        "\n",
        "        inv_output = 1 / output\n",
        "        inv_target = 1 / target\n",
        "        abs_inv_diff = (inv_output - inv_target).abs()\n",
        "        self.irmse = math.sqrt((torch.pow(abs_inv_diff, 2)).mean())\n",
        "        self.imae = float(abs_inv_diff.mean())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir('/content/gdrive/My Drive'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26HNalXjNu3J",
        "outputId": "8248f921-2d72-4eba-d9d9-a7112dc6b223"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['verslag tv week journaal 2.doc', 'boekbespreking 2012.ppt', 'boekbespreking Olaf(2012).doc', 'vleugels.doc', 'ssdfsdasfsd.doc', 'trefwoordenspreekbeurtolaf.TIF', 'Hallo allemaal ik doe.doc', 'sint.pdf', 'turbu2.pdf', 'sinterklaastekening.pdf', 'ffff.jpg', 'dfasdfds.xps', 'Beste Sam.doc', 'spreekbeurt saxofoon', 'Beste Sam.gdoc', 'boekbespreking 2012.gslides', '~$llo allemaal ik doe.doc', 'woorden taalschat 456.docx', 'moederdag 2014 van olaf.pptx', 'funda romana.docx', 'verhaal hades.docx', 'lets try.zip', 'sudoku duits.docx', 'drama scene Aristoteles.docx', 'Planning Olaf periode 2.xlsx', 'Mijn film.mp4', 'iest.mp4', 'werkstuk lijmen Het been reynaert de vos Door Arthur van Dijk Lars van den Bosch en Olaf Verburg.docx', 'Indeling Helpende ouders onderlinge westrijden 2016-2017.doc', 'ne.gdoc', 'wholla.png', 'muziek shizzldizzl.gslides', 'Copy of muziek shizzldizzl.gslides', 'Fruitvliegen.gdoc', 'Programmaboekje Romereis 2017_Athena 1.pdf', 'david donatello, door Larsvdb Olafv.pptx', 'ne', 'frankenstein.gslides', 'Bio pepsine verslag.docx', 'Bio pepsine verslag.docx.gdoc', 'IMG_20180110_171415938.jpg', 'IMG_20180110_160852073.jpg', 'IMG_20180110_163008882.jpg', 'Export November 2017 Olaf verburg.xlsx', 'Export November 2017 Olaf verburg.xlsx.gsheet', 'IMG_20180110_171415938.jpg.gdoc', 'zomertrainingen 2017.pdf', 'E-Ticket_16s-jdesgo7v.png', 'LISTENING-14720.mp3', 'English poetry .gdoc', 'muziek.gslides', 'Nederlands ventoux.gdoc', 'bio kook opdracht.gdoc', 'ventoux info.docx', 'ventoux info.docx.gdoc', 'ventouc presentatie.pptx', 'ventouc presentatie.pptx.gslides', 'letter to the editor I by Olaf Verburg.docx', 'letter to the editor I by Olaf Verburg.docx.gdoc', 'maatschappij leer pluriformiteit - Column chart 1 (1).gsheet', 'maatschappij leer pluriformiteit - Column chart 1.gsheet', 'maatschappijleer pluriformiteit.gdoc', 'maatschappijleer referaat.gslides', 'bio psy - Line chart 1.gsheet', 'bio psy.gdoc', 'Untitled document (3).gdoc', 'bob mintzer', 'Naamloos document (1).gdoc', 'Naamloos document.gdoc', '01 - Shuffle De Funk - Bokb Mintzerr.wav', 'Boarding Pass.pdf', 'Reünie SGL saxofoon.pdf', 'Reünie SGL saxofoon.gdoc', 'Vergelijking engels.gdoc', 'referaat ne.gdoc', 'PWS', 'Limieten_Uithof_2017-18.pdf', 'pws 6-4 photoproduct.png', 'Untitled document (2).gdoc', 'chanson.PNG', 'chansonpourmilanchart.pdf', 'Untitled presentation.gslides', 'Untitled document (1).gdoc', 'Analyse chanson pour milan.gdoc', 'akkoorden_blues_shuffle.mscz', 'gvd.docx', 'gvd.gdoc', 'miguel stand.gsheet', '_life_of_pi_full_text_pdf.pdf', 'IMG_20190108_0004.pdf', 'IMG_20190108_0003.pdf', 'IMG_20190108_0002.pdf', 'IMG_20190108_0001.pdf', 'ROT_blues shuffle.pdf', 'Balansverslag Olaf Verburg 6P.gdoc', 'Untitled document.gdoc', \"motto's en opdrachten literatuur.docx\", 'Oefentoets mod 2.docx', 'Oefentoets mod 2.gdoc', 'engels vergelijking.gdoc', 'Partituur compositie Olaf Verburg.pdf', 'opname compositie Olaf Verburg.mp3', 'WB project groep 53', 'rupsklimmer WB53.mp4', 'IMG_20191204_0001.pdf', 'Copy of Hypixel SkyBlock Minions Sheet v1.27.gsheet', 'Kopie van Russell C. Hibbeler - Mechanics of Materials in SI Units-Pearson (2018).pdf', 'WOP2 MATERIAALKUNDE SAMENVATTING.pdf', 'TentamenAnalyse2CT19-20_Opl (1).pdf', 'TentamenAnalyse2CT19-20_Opl.pdf', 'experiment 14.gsheet', 'online speurtocht.gdoc', 'Takeout', 'minor bend and break group 7', 'Group 7 settlement-4.png', 'flow chart recycling.drawio', 'Group7_Asphalt Report Group 7_feedback.pdf', 'Masonry Schedule v1.1.pdf', 'Rooster Q2 Bend en Break versie 19 okt 2021.pdf', 'big band highlights', 'IMG_20220131_0002.pdf', 'draaiboek.gdoc', 'pdfcoffee.com_advanced-jazz-conception-for-saxophone-pdf-free.pdf', '16623880719538515545954155861703.jpg', 'Belt dump ', 'Fakka Vaka.gsheet', 'Colab Notebooks', 'Deep learning reproduction ', 'churchsong_bobmintzer.aac', 'Kopie van Olaf.mp3', 'Video van Olaf Verburg', 'mdp', 'Story line.gdoc', 'CV_LTH_pre-training_depth-estimation_experiments', 'dataset']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "KXHM6JDgM9d7"
      },
      "outputs": [],
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                    std=[0.229, 0.224, 0.225])\n",
        "\n",
        "transform=transforms.Compose([\n",
        "            transforms.Resize(250),\n",
        "            transforms.CenterCrop((228,304)),\n",
        "            transforms.ToTensor(),\n",
        "            \n",
        "        ])\n",
        "# transform(h5_loader(valdir+the_list[0])[0])\n",
        "# optimizer=torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.01,weight_decay=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FWV7eKVqM9d8"
      },
      "outputs": [],
      "source": [
        "traindir=\"/content/gdrive/My Drive/dataset/train/\"\n",
        "valdir=\"/content/gdrive/My Drive/dataset/val/\"\n",
        "train_list=os.listdir(traindir)\n",
        "val_list=os.listdir(valdir)\n",
        "the_list=train_list[:120]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "P53LjO1TM9d8",
        "outputId": "da397264-4227-4a47-e795-c6022ed8351e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n",
            "failed list index out of range\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-476358906886>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mdepth_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mim_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mim_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mdepth_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# im_tensor=torch.Tensor(np.array(im_tensor))#.transpose(1,3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[50, 3, 228, 304]' is invalid for input of size 4158720"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "avg=0\n",
        "batchsize=50\n",
        "rho=0.01\n",
        "end = time.time()\n",
        "for i,img_path in enumerate(the_list[::batchsize]):\n",
        "    \n",
        "    im_list=torch.Tensor().to(device)\n",
        "    depth_list=torch.Tensor().to(device)\n",
        "    i=batchsize*i\n",
        "    for id in range(i,i+batchsize):\n",
        "        try:\n",
        "            \n",
        "            im,depth=h5_loader(traindir+the_list[id])\n",
        "        except Exception as error:\n",
        "            print('failed', error)\n",
        "            pass\n",
        "        else:\n",
        "            im=transform(im).to(device)\n",
        "            # depth=transforms.ToTensor()(depth)\n",
        "            # depth=normalize(depth)\n",
        "            depth=transform(depth).to(device)\n",
        "            im_list=torch.cat((im_list,im)).to(device=device)\n",
        "            depth_list=torch.cat((depth_list,depth)).to(device=device)\n",
        "    \n",
        "    im_tensor=im_list.reshape((batchsize,*im.shape))\n",
        "    depth_list=depth_list.reshape((batchsize,*depth.shape))\n",
        "    # im_tensor=torch.Tensor(np.array(im_tensor))#.transpose(1,3)\n",
        "    print(im_tensor.shape)\n",
        "    target=depth_list\n",
        "\n",
        "    data_time = time.time() - end\n",
        "    end =time.time()\n",
        "    output=model(im_tensor)\n",
        "    print(output.shape)\n",
        "    # print(im_tensor.shape,depth_tensor.shape,output.shape)\n",
        "    loss = criterion(output,target)\n",
        "    avg=(avg*(1-rho)+loss*rho)/(1-rho**(i+0.5))\n",
        "    print(loss,avg)\n",
        "    \n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    gpu_time = time.time() - end\n",
        "\n",
        "    # measure accuracy and record loss\n",
        "    result = Result()\n",
        "    result.evaluate(output.data, target.data)\n",
        "    # average_meter.update(result, gpu_time, data_time, input.size(0))\n",
        "    end = time.time()\n",
        "    clear_output(wait=True)\n",
        "    # cv2.imshow('image',output[0].detach().numpy())\n",
        "    # cv2.imshow('original',target[0].numpy())\n",
        "    # cv2.imshow('ori image',im_tensor[0].transpose(0,2).numpy())\n",
        "    # cv2.waitKey(1)\n",
        "    # print(im_tensor.shape)\n",
        "\n",
        "\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmqgysHxM9d9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2fZSn6kM9d9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}