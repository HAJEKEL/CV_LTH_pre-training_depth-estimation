<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
    <title>Computer vision by deeplearning</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <noscript>
        <link rel="stylesheet" href="assets/css/noscript.css" />
    </noscript>

</head>

<body class="is-preload">

    <!-- Wrapper -->
    <div id="wrapper" class="fade-in">

        <!-- Intro -->
        <div id="intro">
            <h1>Computer vision by deeplearning </h1>
            <h2>The Lottery Tickets Hypothesis for Supervised
                Pre-training in depth estimation models.</h2>
            <p>
                <a href="https://www.linkedin.com/in/henk-jekel-748054259/" target="_blank">
                    <img src="images/linkedin_icon.png" alt="LinkedIn Pictogram" width="35" height="35">
                </a>
                <a href="https://github.com/HAJEKEL/pt.darts" target="_blank">
                    <img src="images/github_icon.png" alt="Github Pictogram" width="35" height="35">
                </a>
                <a href="mailto:hendrikjekel@gmail.com" target="_blank">
                    <img src="images/gmail_icon.png" alt="Gmail Pictogram" width="35" height="35">
                </a>
            </p>
            <ul class="actions">
                <li>
                    <h4>Keep reading to learn more</h4>
                    <a href="#nav" class="button icon solid solo fa-arrow-down scrolly">Continue</a>
                </li>
            </ul>
        </div>


        <!-- Nav -->
        <nav id="nav">
            <ul class="links">
                <li class="active">
                    <a href="https://hajekel.github.io/">
                        <span style="font-size: 35px;">&larr;</span> Back to portfolio
                    </a>
                </li>
            </ul>




            <ul class="icons">
                <li><a href="https://www.linkedin.com/in/henk-jekel-748054259/"
                        class="icon brands alt fa-linkedin"><span class="label">LinkedIn</span></a>
                </li>
                <li><a href="https://www.kaggle.com/hajekel" class="icon brands fa-kaggle"><span
                            class="label">Kaggle</span></a></li>
                <li><a href="https://github.com/HAJEKEL" class="icon brands alt fa-github"><span
                            class="label">GitHub</span></a></li>
            </ul>
        </nav>

        <!-- Main -->
        <div id="main">

            <!-- Featured Post -->
            <article class="post featured">
                <header class="major">
                    <span class="date">April 28, 2023</span>
                    <h1>Computer vision by deeplearning </h1>
                </header>
                <h2>The Lottery Tickets Hypothesis for Supervised
                    Pre-training in depth estimation models. </h2>
                <!-- 
                <a class="image fit"><img src="images/EP50-reduce.png" alt="EP50-reduce" /></a>
                -->
                <h2>
                    Abstract
                </h2>
                <p>
                    Abstract:

                    In the field of computer vision, pre-trained models have gained renewed attention, particularly in
                    the realm of ImageNet supervised pre-training. Recent studies have highlighted the enduring
                    significance of the Lottery Tickets Hypothesis (LTH) in the context of classification, detection,
                    and segmentation tasks. Inspired by this, we set out to explore the potential of LTH in the
                    pre-training paradigm of depth estimation. Our aim is to investigate whether we can significantly
                    reduce the complexity of pre-trained models without compromising their downstream transferability in
                    the depth estimation task. Through extensive experimentation, we consistently identify highly sparse
                    matching subnetworks within pre-trained weights obtained from ImageNet classification. These
                    subnetworks demonstrate universal transferability to the depth estimation task, maintaining
                    performance comparable to that of the full pre-trained models. Our findings reinforce the relevance
                    of LTH in the pre-training paradigm of depth estimation, paving the way for more efficient and
                    effective depth estimation models.

                </p>
                <h2>
                    Introduction
                </h2>
                <p>
                    In the realm of computer vision, the resurgence of interest in pre-trained models, including
                    classical ImageNet supervised pre-training, has sparked enthusiasm. Recent studies suggest that the
                    core observations of the Lottery Tickets Hypothesis (LTH) remain relevant in the pre-training
                    paradigm of classification, detection, and segmentation tasks (Chen et al., Year). Additionally,
                    Jonathan Frankle and Michael Carbin's paper, "The Lottery Tickets Hypothesis for Supervised and
                    Self-supervised Pre-training in Computer Vision Models," contributes valuable insights to this
                    hypothesis.

                    Driven by curiosity, we pose the following question: Can we aggressively trim down the complexity of
                    pre-trained models without compromising their downstream transferability on the depth estimation
                    task?

                    In this engaging blog post, we explore the concept of supervised pre-trained models through the lens
                    of the Lottery Tickets Hypothesis (LTH) (Frankle & Carbin, 2020). LTH identifies highly sparse
                    matching subnetworks that can be trained almost from scratch and still achieve comparable
                    performance to the full models. Extending the scope of LTH, we investigate whether such matching
                    subnetworks exist in pre-trained computer vision models, specifically examining their transfer
                    performance in the context of depth estimation.

                    Our extensive experiments deliver an overall positive message: from the pre-trained weights obtained
                    through ImageNet classification, we consistently identify matching subnetworks at RESULT% to RESULT%
                    sparsity. These subnetworks demonstrate universal transferability to the depth estimation task,
                    exhibiting performance that remains on par with using the full pre-trained weights. Our findings
                    affirm the general relevance of the core observations of LTH within the pre-training paradigm of
                    depth estimation. The codes and pre-trained models used in our experiments can be accessed on
                    GitHub: https://github.com/HAJEKEL/CV_LTH_pre-training_depth-estimation.

                    Join us on this fascinating journey as we uncover the untapped potential of pre-trained models and
                    shed light on the intriguing relationship between the Lottery Tickets Hypothesis and depth
                    estimation in computer vision.

                    References:
                    Frankle, J., & Carbin, M. (2020). The Lottery Tickets Hypothesis for Supervised and Self-supervised
                    Pre-training in Computer Vision Models.

                    Chen, T., Frankle, J., Chang, S., Liu, S., Zhang, Y., Carbin, M., & Wang, Z. (Year). The Lottery
                    Tickets Hypothesis for Supervised and Self-supervised Pre-training in Computer Vision Models.
                </p>

                <h2>
                    Literature research
                </h2>

                <h3> Lottery ticket hypothesis</h3>

                <p>
                    During his PhD research, Jonathan Frankle conducted a thorough investigation into the lottery ticket
                    hypothesis. Initially, the hypothesis proposed that it was feasible to identify sparse subnetworks
                    within dense networks that would perform comparably to the dense network after training. This
                    approach relied on iterative magnitude pruning, where the network was trained until convergence.
                    Subsequently, all weights below a certain magnitude threshold were pruned, and the remaining weights
                    were reset to their initial random values. This process was repeated until the desired sparsity
                    level was achieved, while still preserving the performance of the dense model.

                    However, it was later revealed that this hypothesis did not hold for larger models. As a result,
                    Frankle put forth a modified hypothesis that was applicable to larger models. Instead of resetting
                    the weights to their original random initialization, he proposed resetting them to an earlier point
                    in the training process. This breakthrough led to the publication of the influential paper "Linear
                    Mode Connectivity and the Lottery Ticket Hypothesis," which demonstrated that regardless of the
                    stochastic gradient descent (SGD) noise, models would converge to the same linearly connected
                    minimum when initialized at an early training point.

                    Building upon these seminal findings, our study focuses on applying this second approach in the
                    context of a large ResNet-50 model trained on ImageNet. We employ iterative magnitude pruning, where
                    the remaining weights are iteratively reset to an early point in training. Specifically, we
                    investigate the application of this resetting method in iterative magnitude pruning for pre-trained
                    classification models on ImageNet. Furthermore, we utilize the obtained weight mask to validate that
                    the downstream transferability for depth estimation is not compromised.

                    By delving into the implications of the modified lottery ticket hypothesis and leveraging the
                    iterative magnitude pruning technique on a pre-trained model, our research aims to provide
                    compelling evidence supporting the preservation of downstream transferability in the realm of depth
                    estimation.
                </p>

                <h2>
                    Methods
                </h2>
                <p>
                    This section descripes the experiments done. First the models used are described after which the exact 
                    mask used will be described. The final part of this section describes all specifics about the 
                    training procedure.
                </p>
                <h3>
                    Model
                </h3>
                <p>
                    For the experiments the FCRN model architecture will be used, this model architecture was proposed by Laina et al. (2016), 
                    the model uses ResNet-50 as a base and a self-designed upsampling end. Instead of the fully connected end layer, 
                    which is used for pre-training, the model has upsampling blocks to generate the 2D depth estimation output.
                </p>
                <figure>
                    <img src="images/model_architecture.png" alt="Model" style="width:100%">
                    <figcaption>Fig.1 - Complete model architecture including the base ResNet-50 model (first two lines) and the new upsampling blocks (Laina et al.,2016).</figcaption>
                  </figure>
                <h4>
                    Masking
                </h4>
                    As described above, we want to combine the proposed model, with the masking of the lottery hypothesis paper. These models were aquired by 
                <h3>
                    Dataset
                </h3>
                <p>
                    The dataset used
                </p>
                <h3>
                    Training procedure
                </h3>
                <p>
                    For training we created our own pipeline to connect the dataset and the model. A To make sure that the masked model 
                    remained masked, the gradients calculated from the l
                </p>

                <h2>
                    Results
                </h2>
                <p>
                    Qualitive and quantitive
                </p>
                <h2>
                    References
                </h2>
                <p>
                    Laina, I., Rupprecht, C., Belagiannis, V., Tombari, F., & Navab, N. (2016). 
                    Deeper Depth Prediction with Fully Convolutional Residual Networks. https://doi.org/10.1109/3dv.2016.32
                    L. Zwald and S. Lambert-Lacroix. The berhu penalty and the
                    grouped effect. arXiv preprint arXiv:1207.6868, 2012. 2, 4,
                    5
                </p>
                <!-- 

                <p>
                    DARTS (Differentiable Architecture Search) is a method for automating the search for neural
                    network architectures. The goal is to find the best architecture for a given task without
                    requiring human expertise in designing neural networks.

                    In the search stage, the DARTS algorithm uses a differentiable relaxation of the architecture
                    search space to learn the best architecture. This involves learning the weights of the different
                    network operations in the architecture. The operations out of which DARTS could choose where
                    DSConv,
                    MBConv and Fused-MBConv.

                    The DARTS search was based on the Fashion-MNIST dataset. The Fashion-MNIST dataset is a popular
                    benchmark dataset used in machine learning and computer vision research. It consists of 70,000
                    grayscale images of 28x28 pixels each, divided into 10 classes, with 7,000 images per class. The
                    classes include T-shirts/tops, trousers, pullovers, dresses, coats, sandals, shirts, sneakers,
                    bags, and ankle boots. The dataset is a more challenging alternative to the classic MNIST
                    dataset, as it features more complex images with greater variability in the appearance of the
                    different classes.

                    It is worth noting that the distribution of the classes is roughly balanced, with each class
                    accounting for 10% of the dataset. This makes the dataset suitable for evaluating the
                    performance of machine learning algorithms in a multi-class classification setting.

                    In the context of DARTS (Differentiable Architecture Search), the terms "normal" and "reduce"
                    are used to refer to two distinct types of cells that are utilized in the process of
                    architecture search.

                    A "normal" cell is defined as a cell that maintains an unchanged spatial resolution between the
                    input and output, whereas a "reduce" cell is a cell that reduces the spatial resolution between
                    the input and output.

                    More details on DARTS in the downloadable pdf:

                </p>
                <ul class="actions special">
                    <li><a href="DARTS.pdf" class="button large">Download PDF</a></li>
                </ul>

                <h2>
                    Results
                </h2>

                <p>
                    The experiments conducted involved training DARTS on the FashionMNIST dataset for 50 epochs,
                    utilizing the only available operations DSConv, MBConv, and Fused-mbconv. Two visualizations of
                    the training process were presented, which included a gif that displayed the progress of each
                    epoch for both the normal and reduce cells. Additionally, an image was provided that contained
                    two plots demonstrating the progress of the training: the first plot indicated the progression
                    of the loss throughout the training process, while the second plot showed the corresponding
                    accuracy progression. These visualizations and plots were indicative of the effectiveness and
                    efficiency of the training process, and demonstrated the potential of DARTS to be employed in
                    real-world tasks.





                    <a class="image fit"><img src="images/normal.gif" alt="normal" /></a>
                    <a class="image fit"><img src="images/reduce.gif" alt="reduce" /></a>
                    <a class="image fit"><img src="images/loss_accuracy.png" alt="loss_accuracy" /></a>

                    The training log can be found on github:
                <ul class="actions special">
                    <li><a href="https://github.com/HAJEKEL/pt.darts/blob/master/searchs/fashionmnist/fashionmnist.log"
                            class="button large">Visit training log</a></li>
                </ul>


                </p>

                <h2>
                    Conclusion
                </h2>


                <p>
                </p>

                <h2>
                    Code implementation
                </h2>

                <p>
                    Code for this blog:
                <ul class="actions special">
                    <li><a href="https://github.com/HAJEKEL/CV_LTH_pre-training_depth-estimation/tree/website"
                            class="button large">WEBSITE</a></li>
                </ul>
                <p> Code to reproduce the fine tuning using google colab and google compute engine:
                </p>
                <ul class="actions special">
                    <li><a href="https://github.com/HAJEKEL/CV_LTH_pre-training_depth-estimation/tree/main"
                            class="button large">TRAINING</a></li>
                </ul>
                <p> Code for the pre-training of Resnet-50 on imagenet:
                </p>
                <ul class="actions special">
                    <li><a href="https://github.com/HAJEKEL/CV_LTH_Pre-training" class="button large">DARTS</a></li>
                </ul>
                </p>

            </article>


        </div>

        <!-- Footer -->
        <footer id="footer">

            <section class="split contact">
                <section class="alt">
                    <h3>Address</h3>
                    <p>Delft, Netherlands<br />
                </section>

                <section>
                    <h3>Email</h3>
                    <p><a>hendrikjekel@gmail.com</a></p>
                </section>
                <section>
                    <h3>Social</h3>
                    <ul class="icons">
                        <li><a href="https://www.linkedin.com/in/henk-jekel-748054259/"
                                class="icon brands alt fa-linkedin"><span class="label">LinkedIn</span></a>
                        </li>
                        <li><a href="https://github.com/HAJEKEL" class="icon brands alt fa-github"><span
                                    class="label">GitHub</span></a></li>
                    </ul>
                </section>
            </section>
        </footer>

        <!-- Copyright -->
        <div id="copyright">
            <ul>
                <li>Henk Jekel &copy; 2022</li>
                <li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
            </ul>
        </div>

    </div>

    <!-- Scripts -->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.scrollex.min.js"></script>
    <script src="assets/js/jquery.scrolly.min.js"></script>
    <script src="assets/js/browser.min.js"></script>
    <script src="assets/js/breakpoints.min.js"></script>
    <script src="assets/js/util.js"></script>
    <script src="assets/js/main.js"></script>

</body>

</html>